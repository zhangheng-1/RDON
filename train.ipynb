{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import yaml\n",
    "import sys\n",
    "sys.path.append(\"./utils/\")\n",
    "from utilities import *\n",
    "from Adam import Adam\n",
    "from dataload import *\n",
    "from RealNVP3D_DeepONet import *\n",
    "from fwd_inv_loss import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device_name = torch.cuda.get_device_name(0)\n",
    "    print(f\"Your GPU model: {device_name}\")\n",
    "else:\n",
    "    print(\"No GPU available.\")\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load MT data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file_name = \"train_32_32.yml\"\n",
    "with open(config_file_name, 'r') as f:\n",
    "    args = yaml.safe_load(f)\n",
    "\n",
    "size = 1024\n",
    "\n",
    "# Load the data\n",
    "TRAIN_PATH = args[\"TRAIN_PATH\"]\n",
    "TEST_PATH = args[\"TEST_PATH\"]\n",
    "ntrain = args['ntrain']\n",
    "ntest  = args['ntest']\n",
    "s_train = args['s_train']\n",
    "r_train = args['r_train']\n",
    "s_test = args['s_test']\n",
    "r_test = args['r_test']\n",
    "batch_size = args['batch_size']\n",
    "n_out = args['n_out']\n",
    "################################################################\n",
    "# load data and data normalization\n",
    "################################################################\n",
    "loc_train,loc_test,x_train,y_train,x_test,y_test,freq_base,obs_base, y_normalizer,x_normalizer = \\\n",
    "        get_batch_data(TRAIN_PATH, TEST_PATH, ntrain, ntest,\\\n",
    "                        r_train, s_train,r_test,s_test,batch_size,n_out)\n",
    "################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train data\n",
    "x_train = x_train.reshape(ntrain,-1)\n",
    "y_train = y_train[:,:,:,0].reshape(ntrain,-1)\n",
    "\n",
    "u_t2 = x_train.reshape(ntrain,1,32,32)\n",
    "y_t2 = loc_train.unsqueeze(0)\n",
    "\n",
    "y_t2 = y_t2.repeat(ntrain, 1, 1)\n",
    "s_t2 = y_train.reshape(ntrain, 1024, 1)\n",
    "\n",
    "print(\"u_t2 shape:\", u_t2.shape)\n",
    "print(\"y_t2 shape:\", y_t2.shape)\n",
    "print(\"s_t2 shape:\", s_t2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## test data\n",
    "x_test = x_test.reshape(ntest,-1)\n",
    "y_test = y_test[:,:,:,0].reshape(ntest,-1)\n",
    "\n",
    "u_t3 = x_test.reshape(ntest,1,32,32)\n",
    "y_t3 = loc_test.unsqueeze(0)\n",
    "\n",
    "\n",
    "y_t3 = y_t3.repeat(ntest, 1, 1)\n",
    "s_t3 = y_test.reshape(ntest, 1024, 1)\n",
    "\n",
    "\n",
    "print(\"u_t3 shape:\", u_t3.shape)\n",
    "print(\"y_t3 shape:\", y_t3.shape)\n",
    "print(\"s_t3 shape:\", s_t3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data set\n",
    "op_batch_size = 64\n",
    "\n",
    "\n",
    "operator_dataset = Onet_dataset(u_t2,y_t2,s_t2)\n",
    "operator_dataset = DataLoader(operator_dataset,batch_size = op_batch_size,shuffle = True)\n",
    "\n",
    "operator_dataset_test = Onet_dataset(u_t3,y_t3,s_t3)\n",
    "operator_dataset_test = DataLoader(operator_dataset_test,batch_size = op_batch_size,shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = output_dim = 1024\n",
    "query_dim = 2\n",
    "layer_sizes_trunk= [query_dim]+[128]*5+[output_dim]\n",
    "\n",
    "activation=\"leaky_relu\"\n",
    "kernel_initializer=\"Glorot normal\"\n",
    "\n",
    "Model = DeepONetCartesianProd(layer_sizes_trunk, activation, kernel_initializer ).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 400\n",
    "learning_rate = 1e-3\n",
    "step_size = 10\n",
    "gamma = 0.95\n",
    "\n",
    "optimizer = Adam(Model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_interval = 20  \n",
    "\n",
    "save_dir = \"Model/1\"\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "\n",
    "with open('Model/1/1.txt', 'w') as file:\n",
    "    record_interval = 1 \n",
    "    for epoch in range(epochs):  \n",
    "        train_loss = 0\n",
    "        total_operator_loss = 0  \n",
    "        total_INV_loss = 0  \n",
    "\n",
    "        Model.train()  \n",
    "        for (u_op, y_op, Guy_op) in operator_dataset:\n",
    "            x_op = y_op[:,:,0]\n",
    "            t_op = y_op[:,:,1]\n",
    "\n",
    "            (u_op, x_op, t_op, Guy_op) = (u_op.to(device), x_op.to(device), t_op.to(device), Guy_op.to(device))\n",
    "\n",
    "            OP_loss =  OP_residual_calculator(u_op, x_op, t_op, Guy_op, Model)\n",
    "            INV_loss = loss_inv(Guy_op, x_op, t_op, u_op, Model)\n",
    "\n",
    "            loss =   OP_loss  + INV_loss \n",
    "\n",
    "            train_loss += loss.item()\n",
    "                 \n",
    "            total_operator_loss += OP_loss.item()\n",
    "            total_INV_loss += INV_loss.item()\n",
    "\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        average_OP_loss = total_operator_loss / ntrain               \n",
    "        average_INV_loss = total_INV_loss / ntrain                   \n",
    "\n",
    "\n",
    "        Model.eval() \n",
    "        test_loss = 0\n",
    "        total_test_OP_loss = 0\n",
    "        total_test_INV_loss = 0\n",
    "\n",
    "        with torch.no_grad(): \n",
    "            for (u_op_test, y_op_test, Guy_op_test) in operator_dataset_test:\n",
    "                x_op_test = y_op_test[:,:,0]\n",
    "                t_op_test = y_op_test[:,:,1]\n",
    "\n",
    "                (u_op_test, x_op_test, t_op_test, Guy_op_test) = (u_op_test.to(device), x_op_test.to(device), t_op_test.to(device), Guy_op_test.to(device))\n",
    "\n",
    "                test_OP_loss = OP_residual_calculator(u_op_test, x_op_test, t_op_test, Guy_op_test, Model)\n",
    "                test_INV_loss = loss_inv(Guy_op_test, x_op_test, t_op_test, u_op_test, Model)\n",
    "\n",
    "                test_loss += (test_OP_loss + test_INV_loss).item()\n",
    "                total_test_OP_loss += test_OP_loss.item()\n",
    "                total_test_INV_loss += test_INV_loss.item()        \n",
    "\n",
    "        average_test_OP_loss = total_test_OP_loss / ntest\n",
    "        average_test_INV_loss = total_test_INV_loss / ntest\n",
    "    \n",
    "        if epoch % record_interval == 0 or epoch == epochs - 1:                \n",
    "            print(f\"Epoch {epoch}: \"\n",
    "                  f\"Train - Average Operator Loss = {average_OP_loss}, Average INV Loss = {average_INV_loss} | \"\n",
    "                  f\"Test - Average Operator Loss = {average_test_OP_loss}, Average INV Loss = {average_test_INV_loss}\")\n",
    "            file.write(f\"Epoch {epoch}: \"\n",
    "                       f\"Train - Average Operator Loss = {average_OP_loss}, Average INV Loss = {average_INV_loss} | \"\n",
    "                       f\"Test - Average Operator Loss = {average_test_OP_loss}, Average INV Loss = {average_test_INV_loss}\\n\")\n",
    "\n",
    "    \n",
    "        scheduler.step()\n",
    "\n",
    "        if epoch % save_interval == 0 or epoch == epochs - 1:\n",
    "            save_path = os.path.join(save_dir, f\"model_epoch_{epoch}.pth\")\n",
    "            torch.save(Model, save_path)  \n",
    "            print(f\"Model saved at epoch {epoch} to {save_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PDENNEval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
